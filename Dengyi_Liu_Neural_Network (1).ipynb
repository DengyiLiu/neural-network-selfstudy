{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoVK_khiSaNu"
      },
      "source": [
        "# Creating a Neural-Network from scratch\n",
        "> A tutorial to code a neural network from scratch in python using numpy.\n",
        "\n",
        "- toc: false\n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [machinelearning, deeplearning, python3.x, numpy]\n",
        "- image: images/backprop.jpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMy2Lns2SaNw"
      },
      "source": [
        "I will assume that you all know what a artificial neural network is and have a little bit of knowledge about `forward and backward propagation`. Just having a simple idea is enough.\n",
        "\n",
        "> Tip: If you do not know what the above terms are or would like to brush up on the topics, I would suggest going through this amazing [youtube playlist](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) by [3Blue1Brown](https://www.3blue1brown.com/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS4Mt5nXSaNx"
      },
      "source": [
        "> youtube: https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUwIQX0OSaNx"
      },
      "source": [
        "## Setting up Imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nbFaw5sDSaNy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gzip\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0B2QadorSaNz"
      },
      "outputs": [],
      "source": [
        "#hide_input\n",
        "import warnings\n",
        "#np.random.seed(200)\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_WKWVCrSaNz"
      },
      "source": [
        "## Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7fmW761SaNz"
      },
      "source": [
        "For this blog post, we'll use one of the most famous datasets in computer vision, [MNIST](https://en.wikipedia.org/wiki/MNIST_database). MNIST contains images of handwritten digits, collected by the National Institute of Standards and Technology and collated into a machine learning dataset by Yann Lecun and his colleagues. Lecun used MNIST in 1998 in [Lenet-5](http://yann.lecun.com/exdb/lenet/), the first computer system to demonstrate practically useful recognition of handwritten digit sequences. This was one of the most important breakthroughs in the history of AI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V83aZ_CwSaN0"
      },
      "source": [
        "Run the code given below to download the `MNIST` dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkvDPK8hSaN0"
      },
      "source": [
        "```shell\n",
        "wget -P path http://deeplearning.net/data/mnist/mnist.pkl.gz\n",
        "```\n",
        "\n",
        "> Note: the above code snippet will download the dataset to `{path}` so be sure to set the `{path}` to the desired location of your choice. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97YgUb_7SaN1"
      },
      "source": [
        "## Preparing our `train` & `validation` datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czxsHfuLQNrr",
        "outputId": "68f6821d-0137-4881-c8a8-090bf0b9693b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path='/content/drive/My Drive/mnist.npz'):\n",
        "    f = np.load(path)\n",
        "    x_train, y_train = f['x_train'], f['y_train']\n",
        "    x_test, y_test = f['x_test'], f['y_test']\n",
        "    f.close()\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "metadata": {
        "id": "LizC-CYSQtWE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_valid, y_valid) = load_data()"
      ],
      "metadata": {
        "id": "vGNPB4bnQw2g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhosBGUbR-bs",
        "outputId": "a633701b-0ba5-4cf6-860b-2b2d171d7e53"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(60000,784)\n",
        "x_valid = x_valid.reshape(10000,784)"
      ],
      "metadata": {
        "id": "UUd8nP3kSEcS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrA8mw4ZSaN2"
      },
      "source": [
        "To make our life a bit easier we are going to take only the examples that contain a 1 or 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-aKninJFSaN2",
        "outputId": "154e9bc2-48c1-4987-a33b-50ce1b40ce94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12665, 784), (12665, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "zero_mask = [y_train==0] # grab all the index values where 0 is present\n",
        "one_mask = [y_train==1] # grad all the index valus where 1 is present\n",
        "\n",
        "# grab all the 1's and 0's and make training set\n",
        "x_train = np.vstack((x_train[zero_mask], x_train[one_mask]))\n",
        "y_train = np.reshape(y_train, (-1,1))\n",
        "y_train = np.squeeze(np.vstack((y_train[zero_mask], y_train[one_mask]))).reshape(-1,1)\n",
        "\n",
        "x_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5h0cLYjSaN2"
      },
      "source": [
        "**Our training set now has 10610 examples**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "t_A2YyRwSaN2",
        "outputId": "976f75be-34a0-4b9b-d1f0-ea869d9553e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2115, 784), (2115, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "zero_mask = [y_valid==0] # grab all the index values where 0 is present\n",
        "one_mask = [y_valid==1] # grad all the index valus where 1 is present\n",
        "\n",
        "# grab all the 1's and 0's and make training set\n",
        "x_valid = np.vstack((x_valid[zero_mask], x_valid[one_mask]))\n",
        "y_valid = np.reshape(y_valid, (-1,1))\n",
        "y_valid = np.squeeze(np.vstack((y_valid[zero_mask], y_valid[one_mask]))).reshape(-1,1)\n",
        "\n",
        "x_valid.shape, y_valid.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B94tWt_hSaN3"
      },
      "source": [
        "**Our validation set now has 2055 examples**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW5-4JeoSaN3"
      },
      "source": [
        "**Why do we need different training and validation sets ?**\n",
        "\n",
        "Since, this topic requires a different post on it's own I won't be covering it here. But you can get the idea from this above video:\n",
        "\n",
        "> youtube: https://youtu.be/1waHlpKiNyY?t=243"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOL1si5_SaN3"
      },
      "source": [
        "Let's view some example images from our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FOGquDNSSaN3",
        "outputId": "b5aa9c30-08b4-4557-a729-365275f9c221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#collapse \n",
        "plt.imshow(x_train[50].reshape(28,28), cmap=\"gray\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "47cy7e-fSaN3",
        "outputId": "f4049ef9-5fc4-44f1-ff77-41f00af528f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#collapse\n",
        "plt.imshow(x_train[5000].reshape(28,28), cmap=\"gray\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxbdik9sSaN4"
      },
      "source": [
        "## Basic Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wwJDYKpSaN4"
      },
      "source": [
        "For this task we are going to use a very basic model architecture this 2 linear layers and a output layer with 1 unit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "l6o17lKdSaN4"
      },
      "outputs": [],
      "source": [
        "#hide_input \n",
        "import graphviz\n",
        "def gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"' + s + '; }')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV4g-B3jSaN4"
      },
      "source": [
        "## Let's take a deep dive into what this network means:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OovTDfG0SaN4"
      },
      "source": [
        "Let's take at look at all the individual components of this network:\n",
        "- **Linear:**\n",
        "  The linear layer computes the following :      \n",
        "   ```\n",
        "   out = matmul(input,W1) + B1\n",
        "   ```\n",
        "   \n",
        "- **ReLU:** \n",
        "  The relu computes the following:\n",
        "  ```\n",
        "  out = max(0, input)\n",
        "  ```\n",
        "- **Sigmoid:** \n",
        "  The sigmoid computes the following:\n",
        "  ```\n",
        "  out = 1/(1 + e.pow(input))\n",
        "  ```\n",
        "  \n",
        "- **Loss:** \n",
        "  For the loss we are going to use the CrossEntropy Loss which is defined by the follwoing equation:\n",
        "  $$loss= -\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(yhat^{(i)}\\right) + (1-y^{(i)})\\log\\left(1-yhat^{(i)}\\right)) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0Hz5W_PSaN5"
      },
      "source": [
        "**Now that we have our model architecture, let's create the different parts needed to assemble the model:**\n",
        "- linear layer\n",
        "- relu activation\n",
        "- sigmoid activation\n",
        "- loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t5xitF_SaN5"
      },
      "source": [
        "**Let's first try to make some sense of what is happening in the backward and forward pass of our model:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUAn0zdGSaN5"
      },
      "source": [
        "**On paper our forward pass would look something like this:**\n",
        "\n",
        "> Note: `@` in python is the `matrix-multiplication operator`. \n",
        "\n",
        "```python\n",
        "inputs = x_train # original inputs\n",
        "targets = y_train # original targets\n",
        "\n",
        "# forward pass for the 1st linear layer\n",
        "z1 = inputs @ w2 + b2\n",
        "a1 = relu(z1)\n",
        "# forward pass for the 2nd linear layer\n",
        "z2 = a1 @ w2 + b2\n",
        "a2 = relu(z2)\n",
        "# forward pass for the output linear layer\n",
        "z3 = a2 @ w3 + b3\n",
        "pred = a3 = sigmoid(z3) # these are our model predictions \n",
        "# calculate loss between original targets & model predictions\n",
        "loss = loss_fn(a3, targets)\n",
        "```\n",
        "> Note: This is not actual code it's just psuedo-code for understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy2pBPtVSaN5"
      },
      "source": [
        "**Forward pass :**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Cx3jxn20SaN5",
        "outputId": "5f4cf6b3-29b8-49f5-bdcb-0bc1cf220c23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f2ee09b5d60>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"830pt\" height=\"260pt\"\n viewBox=\"0.00 0.00 830.05 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-256 826.0542,-256 826.0542,4 -4,4\"/>\n<!-- X -->\n<g id=\"node1\" class=\"node\">\n<title>X</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X</text>\n</g>\n<!-- linear1 -->\n<g id=\"node2\" class=\"node\">\n<title>linear1</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"126.3968\" cy=\"-180\" rx=\"36.2938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"126.3968\" y=\"-176.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">linear1</text>\n</g>\n<!-- X&#45;&gt;linear1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>X&#45;&gt;linear1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M48.0795,-222.548C61.1044,-215.4718 78.1077,-206.2343 92.9417,-198.1754\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"94.7266,-201.1889 101.8427,-193.3397 91.3849,-195.038 94.7266,-201.1889\"/>\n</g>\n<!-- relu1 -->\n<g id=\"node3\" class=\"node\">\n<title>relu1</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"228.6909\" cy=\"-180\" rx=\"29.795\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"228.6909\" y=\"-176.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">relu1</text>\n</g>\n<!-- linear1&#45;&gt;relu1 -->\n<g id=\"edge2\" class=\"edge\">\n<title>linear1&#45;&gt;relu1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M163.0384,-180C171.3528,-180 180.2247,-180 188.6712,-180\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"188.697,-183.5001 198.6969,-180 188.6969,-176.5001 188.697,-183.5001\"/>\n</g>\n<!-- linear2 -->\n<g id=\"node4\" class=\"node\">\n<title>linear2</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"330.985\" cy=\"-126\" rx=\"36.2938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"330.985\" y=\"-122.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">linear2</text>\n</g>\n<!-- relu1&#45;&gt;linear2 -->\n<g id=\"edge3\" class=\"edge\">\n<title>relu1&#45;&gt;linear2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M251.3933,-168.0156C264.7491,-160.9652 281.8992,-151.9119 296.8574,-144.0156\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"298.6246,-147.0405 305.8341,-139.2769 295.3567,-140.8501 298.6246,-147.0405\"/>\n</g>\n<!-- relu2 -->\n<g id=\"node5\" class=\"node\">\n<title>relu2</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"433.2791\" cy=\"-126\" rx=\"29.795\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"433.2791\" y=\"-122.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">relu2</text>\n</g>\n<!-- linear2&#45;&gt;relu2 -->\n<g id=\"edge4\" class=\"edge\">\n<title>linear2&#45;&gt;relu2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M367.6266,-126C375.941,-126 384.813,-126 393.2594,-126\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"393.2852,-129.5001 403.2852,-126 393.2851,-122.5001 393.2852,-129.5001\"/>\n</g>\n<!-- linear3 -->\n<g id=\"node6\" class=\"node\">\n<title>linear3</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"535.5732\" cy=\"-72\" rx=\"36.2938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"535.5732\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">linear3</text>\n</g>\n<!-- relu2&#45;&gt;linear3 -->\n<g id=\"edge5\" class=\"edge\">\n<title>relu2&#45;&gt;linear3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M455.9815,-114.0156C469.3374,-106.9652 486.4875,-97.9119 501.4456,-90.0156\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"503.2129,-93.0405 510.4224,-85.2769 499.945,-86.8501 503.2129,-93.0405\"/>\n</g>\n<!-- sigmoid -->\n<g id=\"node7\" class=\"node\">\n<title>sigmoid</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"648.9164\" cy=\"-72\" rx=\"40.8928\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"648.9164\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">sigmoid</text>\n</g>\n<!-- linear3&#45;&gt;sigmoid -->\n<g id=\"edge6\" class=\"edge\">\n<title>linear3&#45;&gt;sigmoid</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M572.0596,-72C580.246,-72 589.0788,-72 597.7388,-72\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"597.7766,-75.5001 607.7765,-72 597.7765,-68.5001 597.7766,-75.5001\"/>\n</g>\n<!-- prediction -->\n<g id=\"node8\" class=\"node\">\n<title>prediction</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"773.9585\" cy=\"-72\" rx=\"48.1917\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"773.9585\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">prediction</text>\n</g>\n<!-- sigmoid&#45;&gt;prediction -->\n<g id=\"edge7\" class=\"edge\">\n<title>sigmoid&#45;&gt;prediction</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M690.2064,-72C698.3871,-72 707.1181,-72 715.7395,-72\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"715.7705,-75.5001 725.7704,-72 715.7704,-68.5001 715.7705,-75.5001\"/>\n</g>\n<!-- W1 -->\n<g id=\"node9\" class=\"node\">\n<title>W1</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-180\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-176.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">W1</text>\n</g>\n<!-- W1&#45;&gt;linear1 -->\n<g id=\"edge8\" class=\"edge\">\n<title>W1&#45;&gt;linear1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.1606,-180C62.0928,-180 70.9968,-180 79.7725,-180\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.9495,-183.5001 89.9495,-180 79.9495,-176.5001 79.9495,-183.5001\"/>\n</g>\n<!-- B1 -->\n<g id=\"node10\" class=\"node\">\n<title>B1</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-126\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-122.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">B1</text>\n</g>\n<!-- B1&#45;&gt;linear1 -->\n<g id=\"edge9\" class=\"edge\">\n<title>B1&#45;&gt;linear1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M48.0795,-137.452C61.1044,-144.5282 78.1077,-153.7657 92.9417,-161.8246\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"91.3849,-164.962 101.8427,-166.6603 94.7266,-158.8111 91.3849,-164.962\"/>\n</g>\n<!-- W2 -->\n<g id=\"node11\" class=\"node\">\n<title>W2</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"228.6909\" cy=\"-126\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"228.6909\" y=\"-122.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">W2</text>\n</g>\n<!-- W2&#45;&gt;linear2 -->\n<g id=\"edge10\" class=\"edge\">\n<title>W2&#45;&gt;linear2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M255.8353,-126C264.6212,-126 274.6293,-126 284.4123,-126\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"284.4652,-129.5001 294.4652,-126 284.4651,-122.5001 284.4652,-129.5001\"/>\n</g>\n<!-- B2 -->\n<g id=\"node12\" class=\"node\">\n<title>B2</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"228.6909\" cy=\"-72\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"228.6909\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">B2</text>\n</g>\n<!-- B2&#45;&gt;linear2 -->\n<g id=\"edge11\" class=\"edge\">\n<title>B2&#45;&gt;linear2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M249.8863,-83.1888C263.3588,-90.3009 281.1123,-99.6727 296.573,-107.8342\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"295.367,-111.1553 305.8444,-112.7285 298.6349,-104.9649 295.367,-111.1553\"/>\n</g>\n<!-- W3 -->\n<g id=\"node13\" class=\"node\">\n<title>W3</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"433.2791\" cy=\"-72\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"433.2791\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">W3</text>\n</g>\n<!-- W3&#45;&gt;linear3 -->\n<g id=\"edge12\" class=\"edge\">\n<title>W3&#45;&gt;linear3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M460.4235,-72C469.2095,-72 479.2175,-72 489.0006,-72\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"489.0534,-75.5001 499.0534,-72 489.0534,-68.5001 489.0534,-75.5001\"/>\n</g>\n<!-- B3 -->\n<g id=\"node14\" class=\"node\">\n<title>B3</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"433.2791\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"433.2791\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">B3</text>\n</g>\n<!-- B3&#45;&gt;linear3 -->\n<g id=\"edge13\" class=\"edge\">\n<title>B3&#45;&gt;linear3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M454.4745,-29.1888C467.9471,-36.3009 485.7005,-45.6727 501.1612,-53.8342\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"499.9552,-57.1553 510.4326,-58.7285 503.2231,-50.9649 499.9552,-57.1553\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#hide_input\n",
        "gv('''\n",
        "X->linear1->relu1->linear2->relu2->linear3->sigmoid->prediction\n",
        "\n",
        "W1->linear1\n",
        "B1->linear1\n",
        "\n",
        "W2->linear2\n",
        "B2->linear2\n",
        "\n",
        "W3->linear3\n",
        "B3->linear3\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KT9rJoSgSaN6",
        "outputId": "e14d260f-38a7-45e8-9272-6fbbfc7ecb52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f2ee09b04f0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"306pt\" height=\"98pt\"\n viewBox=\"0.00 0.00 305.58 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-94 301.5848,-94 301.5848,4 -4,4\"/>\n<!-- prediction -->\n<g id=\"node1\" class=\"node\">\n<title>prediction</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"48.0957\" cy=\"-72\" rx=\"48.1917\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"48.0957\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">prediction</text>\n</g>\n<!-- loss_fn -->\n<g id=\"node2\" class=\"node\">\n<title>loss_fn</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"169.8881\" cy=\"-45\" rx=\"37.8943\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"169.8881\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">loss_fn</text>\n</g>\n<!-- prediction&#45;&gt;loss_fn -->\n<g id=\"edge1\" class=\"edge\">\n<title>prediction&#45;&gt;loss_fn</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M89.6691,-62.7836C101.1815,-60.2315 113.7218,-57.4514 125.3935,-54.864\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"126.3737,-58.2317 135.3792,-52.6502 124.8586,-51.3976 126.3737,-58.2317\"/>\n</g>\n<!-- loss -->\n<g id=\"node4\" class=\"node\">\n<title>loss</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"270.5848\" cy=\"-45\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"270.5848\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">loss</text>\n</g>\n<!-- loss_fn&#45;&gt;loss -->\n<g id=\"edge3\" class=\"edge\">\n<title>loss_fn&#45;&gt;loss</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M207.6703,-45C215.989,-45 224.7967,-45 233.1034,-45\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"233.283,-48.5001 243.2829,-45 233.2829,-41.5001 233.283,-48.5001\"/>\n</g>\n<!-- target -->\n<g id=\"node3\" class=\"node\">\n<title>target</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"48.0957\" cy=\"-18\" rx=\"31.3957\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"48.0957\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">target</text>\n</g>\n<!-- target&#45;&gt;loss_fn -->\n<g id=\"edge2\" class=\"edge\">\n<title>target&#45;&gt;loss_fn</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M77.268,-24.4672C91.5846,-27.641 109.1468,-31.5343 125.1152,-35.0743\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"124.8078,-38.5911 135.3283,-37.3385 126.3229,-31.757 124.8078,-38.5911\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#hide_input\n",
        "gv('''\n",
        "prediction->loss_fn\n",
        "target->loss_fn\n",
        "loss_fn-> loss\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqi4l7SHSaN6"
      },
      "source": [
        "**Consequently our backward pass would look something like this :** \n",
        "\n",
        "(Let us assume that the `grad(inp, out)` computes the gradients of `inp` wrt `out`)\n",
        "\n",
        "```python\n",
        "# gradient of loss wrt to the output of the last activation layer: (a3)\n",
        "# (or the predictions of model)\n",
        "da3 = grad(loss, a3)\n",
        "\n",
        "# gradient of loss wrt to the output of the current linear layer: (z3)\n",
        "dz3 = grad(loss, z3) = grad(loss, a3) * grad(a3, z3)\n",
        "# gradient of loss wrt to w3\n",
        "dw3 = grad(loss, w3) = grad(loss, z3) * grad(z3, w3) = dz3 * grad(z3, w3)\n",
        "# gradient of loss wrt to b3\n",
        "db3 = grad(loss, b3) = grad(loss, z3) * grad(z3, b3) = dz3 * grad(z3, b3)\n",
        "# gradient of loss wrt to the input of the current linear layer: (a2)\n",
        "da2 = grad(loss, a2) = grad(loss, a3) = grad(a2, )\n",
        "\n",
        "# gradient of loss wrt to the output of the current linear layer: (z2)\n",
        "dz2 = grad(loss, z2) = grad(loss, a2) * grad(a2, z2) \n",
        "# gradient of loss wrt to w2\n",
        "dw2 = grad(loss, w2) = grad(loss, z2) * grad(z2, w2) = dz2 * grad(z2, w2)\n",
        "# gradient of loss wrt to b2\n",
        "db2 = grad(loss, b2) = grad(loss, z2) * grad(z2, b2) = dz2 * grad(z2, b2)\n",
        "# gradient of loss wrt to the input of the current linear layer: (a1)\n",
        "da1 = grad(loss, a1) = grad(loss, z2) * grad(z2, a1) = dz2 * grad(z2, a1)\n",
        "\n",
        "# gradient of loss wrt to the output of the current linear layer: (z1)\n",
        "dz1 = grad(loss, z1) = grad(loss, a1) * grad(a1, z1) = da1 * grad(a1, z1)\n",
        "# gradient of loss wrt to w1\n",
        "dw1 = grad(loss, w1) = grad(loss, z1) * grad(z1, w1) = dz1 * grad(z1, w1)\n",
        "# gradient of loss wrt to b1\n",
        "db1 = grad(loss, b1) = grad(loss, z1) * grad(z1, 1) = dz1 * grad(z1, b1)\n",
        "# In this layer the inputs are out training examples which we cannot change so\n",
        "# we do not need to commpute more gradients\n",
        "\n",
        "# Update parameters :\n",
        "# since we now have all the required gradients we can now perform the update step\n",
        "w1 -= learning_rate * dw1\n",
        "b1 -= learning_rate * db1\n",
        "\n",
        "w2 -= learning_rate * dw2\n",
        "b2 -= learning_rate * db2\n",
        "```\n",
        "> Note: This is not actual code it's just psuedo-code for understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxbNVk2xSaN6"
      },
      "source": [
        "**Backward pass:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_ldrnBpGSaN6",
        "outputId": "d9cc132e-4b61-47de-9bed-9cedd9992963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f2ee09b01f0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"791pt\" height=\"233pt\"\n viewBox=\"0.00 0.00 791.06 233.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 229)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-229 787.0577,-229 787.0577,4 -4,4\"/>\n<!-- Loss -->\n<g id=\"node1\" class=\"node\">\n<title>Loss</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"28.5975\" cy=\"-153\" rx=\"28.6953\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"28.5975\" y=\"-149.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Loss</text>\n</g>\n<!-- sigmoid -->\n<g id=\"node2\" class=\"node\">\n<title>sigmoid</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"134.1413\" cy=\"-153\" rx=\"40.8928\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"134.1413\" y=\"-149.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">sigmoid</text>\n</g>\n<!-- Loss&#45;&gt;sigmoid -->\n<g id=\"edge1\" class=\"edge\">\n<title>Loss&#45;&gt;sigmoid</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M57.4378,-153C65.3341,-153 74.1374,-153 82.885,-153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"83.0709,-156.5001 93.0709,-153 83.0708,-149.5001 83.0709,-156.5001\"/>\n</g>\n<!-- linear3 -->\n<g id=\"node3\" class=\"node\">\n<title>linear3</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"247.4844\" cy=\"-153\" rx=\"36.2938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"247.4844\" y=\"-149.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">linear3</text>\n</g>\n<!-- sigmoid&#45;&gt;linear3 -->\n<g id=\"edge2\" class=\"edge\">\n<title>sigmoid&#45;&gt;linear3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M175.3814,-153C183.6613,-153 192.417,-153 200.8648,-153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"200.9639,-156.5001 210.9639,-153 200.9638,-149.5001 200.9639,-156.5001\"/>\n</g>\n<!-- W3 -->\n<g id=\"node4\" class=\"node\">\n<title>W3</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"349.7785\" cy=\"-207\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"349.7785\" y=\"-203.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">W3</text>\n</g>\n<!-- linear3&#45;&gt;W3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>linear3&#45;&gt;W3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M272.5084,-166.2099C286.7133,-173.7085 304.5928,-183.1469 319.5745,-191.0556\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"317.9922,-194.178 328.4696,-195.7512 321.26,-187.9876 317.9922,-194.178\"/>\n</g>\n<!-- B3 -->\n<g id=\"node5\" class=\"node\">\n<title>B3</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"349.7785\" cy=\"-153\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"349.7785\" y=\"-149.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">B3</text>\n</g>\n<!-- linear3&#45;&gt;B3 -->\n<g id=\"edge4\" class=\"edge\">\n<title>linear3&#45;&gt;B3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M284.126,-153C293.3729,-153 303.3094,-153 312.5833,-153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"312.7002,-156.5001 322.7001,-153 312.7001,-149.5001 312.7002,-156.5001\"/>\n</g>\n<!-- relu2 -->\n<g id=\"node6\" class=\"node\">\n<title>relu2</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"349.7785\" cy=\"-99\" rx=\"29.795\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"349.7785\" y=\"-95.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">relu2</text>\n</g>\n<!-- linear3&#45;&gt;relu2 -->\n<g id=\"edge5\" class=\"edge\">\n<title>linear3&#45;&gt;relu2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M272.5084,-139.7901C286.1911,-132.5672 303.2833,-123.5444 317.9109,-115.8226\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"319.8974,-118.7317 327.1069,-110.9681 316.6295,-112.5413 319.8974,-118.7317\"/>\n</g>\n<!-- linear2 -->\n<g id=\"node7\" class=\"node\">\n<title>linear2</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"452.0727\" cy=\"-99\" rx=\"36.2938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"452.0727\" y=\"-95.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">linear2</text>\n</g>\n<!-- relu2&#45;&gt;linear2 -->\n<g id=\"edge6\" class=\"edge\">\n<title>relu2&#45;&gt;linear2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M379.9169,-99C387.9651,-99 396.8532,-99 405.5607,-99\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"405.6385,-102.5001 415.6385,-99 405.6384,-95.5001 405.6385,-102.5001\"/>\n</g>\n<!-- W2 -->\n<g id=\"node8\" class=\"node\">\n<title>W2</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"554.3668\" cy=\"-153\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"554.3668\" y=\"-149.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">W2</text>\n</g>\n<!-- linear2&#45;&gt;W2 -->\n<g id=\"edge7\" class=\"edge\">\n<title>linear2&#45;&gt;W2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M477.0966,-112.2099C491.3015,-119.7085 509.1811,-129.1469 524.1628,-137.0556\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"522.5804,-140.178 533.0578,-141.7512 525.8483,-133.9876 522.5804,-140.178\"/>\n</g>\n<!-- B2 -->\n<g id=\"node9\" class=\"node\">\n<title>B2</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"554.3668\" cy=\"-99\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"554.3668\" y=\"-95.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">B2</text>\n</g>\n<!-- linear2&#45;&gt;B2 -->\n<g id=\"edge8\" class=\"edge\">\n<title>linear2&#45;&gt;B2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M488.7143,-99C497.9612,-99 507.8977,-99 517.1715,-99\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"517.2884,-102.5001 527.2884,-99 517.2883,-95.5001 517.2884,-102.5001\"/>\n</g>\n<!-- relu1 -->\n<g id=\"node10\" class=\"node\">\n<title>relu1</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"554.3668\" cy=\"-45\" rx=\"29.795\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"554.3668\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">relu1</text>\n</g>\n<!-- linear2&#45;&gt;relu1 -->\n<g id=\"edge9\" class=\"edge\">\n<title>linear2&#45;&gt;relu1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M477.0966,-85.7901C490.7793,-78.5672 507.8715,-69.5444 522.4992,-61.8226\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"524.4856,-64.7317 531.6951,-56.9681 521.2178,-58.5413 524.4856,-64.7317\"/>\n</g>\n<!-- linear1 -->\n<g id=\"node11\" class=\"node\">\n<title>linear1</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"656.6609\" cy=\"-45\" rx=\"36.2938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"656.6609\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">linear1</text>\n</g>\n<!-- relu1&#45;&gt;linear1 -->\n<g id=\"edge10\" class=\"edge\">\n<title>relu1&#45;&gt;linear1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M584.5051,-45C592.5533,-45 601.4415,-45 610.149,-45\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"610.2267,-48.5001 620.2267,-45 610.2267,-41.5001 610.2267,-48.5001\"/>\n</g>\n<!-- W1 -->\n<g id=\"node12\" class=\"node\">\n<title>W1</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"756.0577\" cy=\"-72\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"756.0577\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">W1</text>\n</g>\n<!-- linear1&#45;&gt;W1 -->\n<g id=\"edge11\" class=\"edge\">\n<title>linear1&#45;&gt;W1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M688.6578,-53.6916C698.9795,-56.4954 710.473,-59.6174 721.0033,-62.4779\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"720.1668,-65.8774 730.7346,-65.1213 722.0018,-59.1222 720.1668,-65.8774\"/>\n</g>\n<!-- B1 -->\n<g id=\"node13\" class=\"node\">\n<title>B1</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"756.0577\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"756.0577\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">B1</text>\n</g>\n<!-- linear1&#45;&gt;B1 -->\n<g id=\"edge12\" class=\"edge\">\n<title>linear1&#45;&gt;B1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M688.6578,-36.3084C698.9795,-33.5046 710.473,-30.3826 721.0033,-27.5221\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"722.0018,-30.8778 730.7346,-24.8787 720.1668,-24.1226 722.0018,-30.8778\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#hide_input\n",
        "gv('''\n",
        "Loss -> sigmoid->linear3\n",
        "linear3->W3\n",
        "linear3->B3\n",
        "linear3->relu2->linear2\n",
        "\n",
        "linear2->W2\n",
        "linear2->B2\n",
        "linear2->relu1->linear1\n",
        "\n",
        "linear1->W1\n",
        "linear1->B1\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITuS2SCVSaN6"
      },
      "source": [
        "### The `Linear` Layer "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTEraqHtSaN6"
      },
      "source": [
        "Below code creates a `Linear class` which represents a `Linear` layer in our neural-network. The `forward function` of the class implements the of the `layer's forward propagation` & the `backward function` implements the `layers's backward propagation`. Let's go to detail into what the code means:\n",
        "\n",
        "- **Forward:**  \n",
        "This part is quite straight-forward it computes the dot-product between the **`input`** and the **`weights`** & adds the **`bias`** term to get **`z`**. It also stores all the intermidiate values generated to use in the backward pass.\n",
        "\n",
        "\n",
        "- **Backward:**\n",
        "    * The backward method of the class **`Linear`** takes in the argument **`grads`**. \n",
        "    * **`grads`** is the gradient of the loss wrt to the output of the current linear layer ie., **`dz`** if we were to follow the nomenclature of our pseudo-code.\n",
        "    * To succesfully compute the backward pass for our linear layer we need the following:\n",
        "        - **`grad(z, w)`** \n",
        "        - **`grad(z, b)`**\n",
        "        - **`grad(z, a_prev)`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2OPJZuISaN7"
      },
      "source": [
        "\n",
        "\n",
        "> Note: `z`, `w`, `b`, `a_prev` are the outputs, weights, bias and input-activations of the Linear layer respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DuiKGGXoSaN7"
      },
      "outputs": [],
      "source": [
        "class Linear:\n",
        "    def __init__(self, w, b):\n",
        "        self.w = w\n",
        "        self.b = b\n",
        "        \n",
        "    def forward(self, inp):\n",
        "        \"\"\"\n",
        "        Implement the linear part of a layer's forward propagation.\n",
        "        \n",
        "        Args:\n",
        "            inp : activations from previous layer (or input data)\n",
        "        \n",
        "        Returns:\n",
        "\n",
        "            z  : the input of the activation function, also called pre-activation parameter \n",
        "        \"\"\"\n",
        "        self.inp = inp\n",
        "        self.z   = inp @ self.w + self.b\n",
        "        return self.z\n",
        "    \n",
        "    def backward(self, grads):\n",
        "        \"\"\"\n",
        "        Implement the linear portion of backward propagation for a single layer.\n",
        "\n",
        "        Args:\n",
        "            grads :  Gradient of the cost with respect to the linear output. \n",
        "                     or the accumulated gradients from the prev layers. \n",
        "                     This is used for the chain rule to compute the gradients.\n",
        "        Returns:\n",
        "            da : Gradient of cost wrt to the activation of the previous layer or the input of the \n",
        "                 current layer.\n",
        "            dw : Gradient of the cost with respect to W\n",
        "            db : Gradient of the cost with respect to b\n",
        "        \"\"\"\n",
        "        m = self.inp.shape[1]\n",
        "        # gradient of loss wrt to the weights\n",
        "        dw = 1/m * (self.inp.T @ grads)\n",
        "        # gradient of the loss wrt to the bias\n",
        "        db = 1/m * np.sum(grads, axis=0, keepdims=True)\n",
        "        # gradient of the loss wrt to the input of the linear layer\n",
        "        # this is used to continue the chain rule\n",
        "        da_prev = grads @ self.w.T \n",
        "        return (da_prev, dw, db)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxQTRwxWSaN7"
      },
      "source": [
        "### The `ReLU` Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7xKlaesSaN7"
      },
      "source": [
        "- **Forward**:  \n",
        "The mathematical formula for ReLU is $A = RELU(Z) = max(0, Z)$\n",
        "- **Backward**:  \n",
        "During the backward pass the relu accepts the gradients of the `loss wrt to the activation` i.e, `da` then computes\n",
        "the gradients of the `loss wrt to the input-of-relu(z)` i.e, `dz`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "W_K0enoISaN7"
      },
      "outputs": [],
      "source": [
        "class RelU:\n",
        "    def forward(self, inp):\n",
        "        \"\"\"\n",
        "        Implement the RELU function.\n",
        "\n",
        "        Args:\n",
        "            inp : Output of the linear layer, of any shape\n",
        "\n",
        "        Returns:\n",
        "            a  : Post-activation parameter, of the same shape as Z\n",
        "        \"\"\"\n",
        "        self.inp = inp\n",
        "        self.output = np.maximum(0, self.inp)\n",
        "        return self.output\n",
        "    \n",
        "    def backward(self, grads):\n",
        "        \"\"\"\n",
        "        Implement the backward propagation for a single RELU unit.\n",
        "\n",
        "        Ars:\n",
        "            grads : gradients of the loss wrt to the activation output\n",
        "\n",
        "        Returns:\n",
        "            dz : Gradient of the loss with respect to the input of the activation\n",
        "        \"\"\"\n",
        "        dz = np.array(grads, copy=True)\n",
        "        dz[self.inp <= 0] = 0\n",
        "        return dz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5pDD6dqSaN7"
      },
      "source": [
        "### The `sigmoid` Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzF-ldv4SaN7"
      },
      "source": [
        "The sigmoid layer functions in exactly the same way as the `ReLU` layer . The only difference is the forward pass output calculation. \n",
        "\n",
        "\n",
        "In the `sigmoid layer`:  $\\sigma(Z) = \\frac{1}{ 1 + e^{-(W A + b)}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LfKtzNXxSaN7"
      },
      "outputs": [],
      "source": [
        "class Sigmoid:\n",
        "    def forward(self, inp):\n",
        "        \"\"\"\n",
        "        Implements the sigmoid activation in numpy\n",
        "\n",
        "        Args:\n",
        "            inp: numpy array of any shape\n",
        "\n",
        "        Returns:\n",
        "            a  : output of sigmoid(z), same shape as inp\n",
        "        \"\"\"\n",
        "        self.inp = inp\n",
        "        self.out =  1/(1+np.exp(-self.inp))\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self, grads):\n",
        "        \"\"\"\n",
        "        Implement the backward propagation for a single sigmoid unit.\n",
        "\n",
        "        Args:\n",
        "            grads : gradients of the loss wrt to the activation output\n",
        "\n",
        "        Returns:\n",
        "            dz : Gradient of the loss with respect to the input of the activation\n",
        "        \"\"\"\n",
        "        s = 1/(1+np.exp(-self.inp))\n",
        "        dz = grads * s * (1-s)\n",
        "        return dz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe2J0sWCSaN8"
      },
      "source": [
        "## `Loss` function :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7e6lDwRSaN8"
      },
      "source": [
        "For this task we are going to use the [CrossEntropy Loss](https://en.wikipedia.org/wiki/Cross_entropy)\n",
        "\n",
        "The `forward` pass of the CrossEntropy Loss is computed as follows: \n",
        "$$loss= -\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(yhat^{(i)}\\right) + (1-y^{(i)})\\log\\left(1-yhat^{(i)}\\right)) $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YHAVU_jHSaN8"
      },
      "outputs": [],
      "source": [
        "class CELoss():\n",
        "    def forward(self, pred, target):\n",
        "        \"\"\"\n",
        "        Implement the CrossEntropy loss function.\n",
        "\n",
        "        Args:\n",
        "            pred   : predicted labels from the neural network\n",
        "            target : true \"label\" labels\n",
        "        Returns:\n",
        "            loss   : cross-entropy loss\n",
        "        \"\"\"\n",
        "        self.yhat = pred\n",
        "        self.y = target\n",
        "        m = self.y.shape[0]\n",
        "        # commpute loss\n",
        "        term1 = (np.multiply(self.y, np.log(self.yhat)))\n",
        "        term2 = (np.multiply((1-self.y),(np.log(1-self.yhat))))\n",
        "        loss = -1/m * np.sum(term1+term2)\n",
        "        self.output = loss\n",
        "        return np.squeeze(self.output) # convert array to a single value number\n",
        "    \n",
        "    def backward(self):\n",
        "        \"\"\"\n",
        "        Computes the gradinets of the loss_fn wrt to the predicted labels\n",
        "        \n",
        "        Returns:\n",
        "         da : derivative of loss_fn wrt to the predicted labels\n",
        "        \"\"\"\n",
        "        # derivative of loss_fn with respect to a [predicted labels]\n",
        "        da = - (np.divide(self.y, self.yhat) - np.divide(1 - self.y, 1 - self.yhat)) \n",
        "        return da"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iysE8AsESaN8"
      },
      "source": [
        "## Model:\n",
        "\n",
        "**Let's go over the architecture that we are going to use for our neural netwok:**\n",
        "\n",
        "- Our model is going to have 2 hidden layers and a output layer. \n",
        "- The 2 `hidden layers` `(linear layers)` are going to have `16 units` each followed by a `ReLU` activation layer and the `output layer` `(linear layer)` is going to have `1 unit` followed by a `Sigmoid` unit. \n",
        "- The output layer is going to predict the `probability` of wether the given input is either a `0` or a `1`. If the predicted probability is `> 0.5 we` will assumse that the `predicted output` is `1` else `0`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq_W28XDSaN8"
      },
      "source": [
        "Let's assemble the layers required to construct out model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1wKjV4GSaN8"
      },
      "source": [
        "**These are our inputs and targets:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Fez5WX97SaN8",
        "outputId": "b54df4a1-2b0c-4a44-9722-90700e2f829e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Inputs: (12665, 784)\n",
            "Shape of Targets: (12665, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x360 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#collapse\n",
        "print(\"Shape of Inputs:\", x_train.shape)\n",
        "print(\"Shape of Targets:\", y_train.shape)\n",
        "\n",
        "fig = plt.figure(figsize=(12,5))\n",
        "for i in range(10):\n",
        "    n = np.random.randint(len(x_train))\n",
        "    val = x_train[n]\n",
        "    ax = plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(val.reshape(28,28), cmap=\"binary\")\n",
        "    plt.title(f\"Target value: {y_train[n].squeeze()}\")\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVB1tcELSaN9"
      },
      "source": [
        "**Initialize model parameters:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "F_ZlSGFWSaN9",
        "outputId": "9186c333-6097-4768-de1c-c130295f17d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((784, 16), (1, 16), (16, 16), (1, 16), (16, 1), (1, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "#hide_output\n",
        "\n",
        "nh1 = 16 # no. of units in the first hidden layer\n",
        "nh2 = 16 # no. of units in the 2nd hidden layer\n",
        "nh3 = 1 # no. of units in the output layer\n",
        "\n",
        "w1  = np.random.randn(x_train.shape[1], nh1) * 0.01\n",
        "b1  = np.zeros((1, nh1))\n",
        "\n",
        "w2  = np.random.randn(nh1, nh2) * 0.01\n",
        "b2  = np.zeros((1, nh2))\n",
        "\n",
        "w3  = np.random.randn(nh2, nh3)\n",
        "b3  = np.zeros((1, nh3))\n",
        "\n",
        "w1.shape, b1.shape, w2.shape, b2.shape, w3.shape, b3.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb1eOHR5SaN9"
      },
      "source": [
        "**Instaniating the layers needed to construct our model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZdEN6loeSaN9"
      },
      "outputs": [],
      "source": [
        "lin1    = Linear(w1,b1) # 1 hidden layer\n",
        "relu1   = RelU()\n",
        "lin2    = Linear(w2,b2) # 2nd hidden layer\n",
        "relu2   = RelU()\n",
        "lin3    = Linear(w3,b3) # output layer\n",
        "sigmoid = Sigmoid()\n",
        "\n",
        "loss_fn = CELoss() # loss_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzfrstD8SaN9"
      },
      "source": [
        "### Forward pass:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WnbB8ZavSaN9",
        "outputId": "b3a00b98-b2af-4461-894e-2015ea873956",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.8564794856801441\n"
          ]
        }
      ],
      "source": [
        "# forward pass\n",
        "z1   = lin1.forward(x_train)\n",
        "a1   = relu1.forward(z1)\n",
        "z2   = lin2.forward(a1)\n",
        "a2   = relu2.forward(z2)\n",
        "z3   = lin3.forward(a2)\n",
        "pred = a3 = sigmoid.forward(z3)\n",
        "\n",
        "# calculate loss\n",
        "loss = loss_fn.forward(pred, y_train)\n",
        "print(\"Loss:\", loss) # print out the loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IfgwtgoSaN-"
      },
      "source": [
        "### Backward pass:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "S_x4xY66SaN-"
      },
      "outputs": [],
      "source": [
        "# backward pass\n",
        "da3 = loss_fn.backward() # gradient of loss wrt to final output\n",
        "dz3 = sigmoid.backward(da3)\n",
        "\n",
        "da2, dw3, db3 = lin3.backward(dz3)\n",
        "\n",
        "dz2 = relu2.backward(da2)\n",
        "da1, dw2, db2 = lin2.backward(dz2)\n",
        "\n",
        "dz1 = relu1.backward(da1)\n",
        "_, dw1, db1 = lin1.backward(da1)\n",
        "\n",
        "# check if the parameters and the gradients are of same shape\n",
        "# so that we can preform the update state\n",
        "assert lin1.w.shape == dw1.shape\n",
        "assert lin2.w.shape == dw2.shape\n",
        "assert lin3.w.shape == dw3.shape\n",
        "\n",
        "assert lin1.b.shape == db1.shape\n",
        "assert lin2.b.shape == db2.shape\n",
        "assert lin3.b.shape == db3.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoD6e8SRSaN-"
      },
      "source": [
        "### Update parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "18TzTJXZSaN-"
      },
      "outputs": [],
      "source": [
        "# set learning rate\n",
        "learning_rate = 0.0002\n",
        "\n",
        "# update parameters \n",
        "lin1.w -= learning_rate * dw1\n",
        "lin2.w -= learning_rate * dw2\n",
        "lin3.w -= learning_rate * dw3\n",
        "\n",
        "lin1.b -= learning_rate * db1\n",
        "lin2.b -= learning_rate * db2\n",
        "lin3.b -= learning_rate * db3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZnwEXkhSaN-"
      },
      "source": [
        "So, this is how our training our model is going to look we first calculate the `loss` of the model during the `forward pass` , then we calculate the gradients of the `loss` wrt to the `parameters` of the model. After which these `gradients` are used to `update the model parameters`. We continue this workflow for a certain number of `iterations` or until our `loss` reaches the desired value.\n",
        "\n",
        "Let's code up a class which will make this steps easir to achieve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyGPYP8tSaN-"
      },
      "source": [
        "### Putting it all together:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "009fKcvuSaN-"
      },
      "source": [
        "- **Initializing parameters:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kWSNVvkySaN_",
        "outputId": "6596e661-67ed-42e8-de9c-985f2e924bb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((784, 16), (1, 16), (16, 16), (1, 16), (16, 1), (1, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#hide_output\n",
        "\n",
        "# Instantiate parameters\n",
        "nh1 = 16 # no. of units in the first hidden layer\n",
        "nh2 = 16 # no. of units in the 2nd hidden layer\n",
        "nh3 = 1 # no. of units in the output layer\n",
        "\n",
        "w1  = np.random.randn(x_train.shape[1], nh1) * 0.01\n",
        "b1  = np.zeros((1, nh1))\n",
        "\n",
        "w2  = np.random.randn(nh1, nh2) * 0.01\n",
        "b2  = np.zeros((1, nh2))\n",
        "\n",
        "w3  = np.random.randn(nh2, nh3)\n",
        "b3  = np.zeros((1, nh3))\n",
        "\n",
        "w1.shape, b1.shape, w2.shape, b2.shape, w3.shape, b3.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stZRZOyLSaN_"
      },
      "source": [
        "For our convenice, we will create a `Model` class . \n",
        "\n",
        "This `Model` class will store all the parameters for our neural-network.\n",
        "The `forward` method will compute the `forward pass` of the network to generate the `loss` (and or `predictions`) of the model. The `backward` method will compute the `backward pass` of the network to get the gradinets of the `loss` wrt to the `parameters` of the model. Finally the `update` method will update the parameters of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xI8fD6JFSaN_"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "    def __init__(self, learning_rate):\n",
        "        \"\"\"\n",
        "        A simple neural network model\n",
        "        The `forward` method computes the forward propagation step of the model\n",
        "        The `backward` method computes the backward step propagation of the model\n",
        "        The `update_step` method updates the parameters of the model\n",
        "        \"\"\"\n",
        "        self.lin1    = Linear(w1,b1) # 1st linear layer\n",
        "        self.relu1   = RelU()        # 1st activation layer\n",
        "        self.lin2    = Linear(w2,b2) # 2nd linear layer\n",
        "        self.relu2   = RelU()        # 2nd activation layer\n",
        "        self.lin3    = Linear(w3,b3) # 3rd linear layer\n",
        "        self.sigmoid = Sigmoid()     # 3rd activation layer\n",
        "        self.loss_fn = CELoss()      # loss_fn\n",
        "        \n",
        "        # learning_rate to update model parameters\n",
        "        self.lr      = learning_rate\n",
        "        # stores the loss at each iteration\n",
        "        self.losses  = [] \n",
        "\n",
        "\n",
        "    def forward(self, inp, calc_loss=True, targ=None):\n",
        "        \"\"\"\n",
        "        Computs the forward step for out model Additionally\n",
        "        it also returns the loss [Optional] and the predictions\n",
        "        of the model.\n",
        "        \n",
        "        Args:\n",
        "            inp       : the training set.\n",
        "            calc_loss : wether to calculate loss of the model if False only predictions\n",
        "                        are calculated.\n",
        "            targ      : the original targets to the training set. \n",
        "        \n",
        "        Note: to calculate the `loss` the `targ` must be given\n",
        "        \n",
        "        Returns:\n",
        "            pred : outputs of the 3rd activation layer.\n",
        "            loss : [Optional] loss the model , if the `targ` is given.\n",
        "        \"\"\"\n",
        "        out  = self.relu1.forward(self.lin1.forward(inp))\n",
        "        out  = self.relu2.forward(self.lin2.forward(out))\n",
        "        pred = self.sigmoid.forward(self.lin3.forward(out))\n",
        "        \n",
        "        if calc_loss:\n",
        "            assert targ is not None, \"to calculate loss targets must be given\"\n",
        "            loss = self.loss_fn.forward(pred, targ)\n",
        "            # appending the loss of the current iteration\n",
        "            self.losses.append(loss)\n",
        "            return loss, pred\n",
        "        else:\n",
        "            return pred\n",
        "        \n",
        "    def _assert_shapes(self):\n",
        "        \"\"\"\n",
        "        Checks the shape of the parameters and the gradients of the model\n",
        "        \"\"\"\n",
        "        assert lin1.w.shape == dw1.shape\n",
        "        assert lin2.w.shape == dw2.shape\n",
        "        assert lin3.w.shape == dw3.shape\n",
        "\n",
        "        assert lin1.b.shape == db1.shape\n",
        "        assert lin2.b.shape == db2.shape\n",
        "        assert lin3.b.shape == db3.shape\n",
        "\n",
        "\n",
        "    def backward(self):\n",
        "        \"\"\"\n",
        "        Computes the backward step\n",
        "        and return the gradients of the parameters with the loss\n",
        "        \"\"\"\n",
        "        da3 = self.loss_fn.backward()\n",
        "        dz3 = self.sigmoid.backward(da3)\n",
        "        da2, dw3, db3 = self.lin3.backward(dz3)\n",
        "        \n",
        "        dz2 = self.relu2.backward(da2)\n",
        "        da1, dw2, db2 = self.lin2.backward(dz2)\n",
        "\n",
        "        dz1 = self.relu1.backward(da1)\n",
        "        _, dw1, db1 = self.lin1.backward(dz1)\n",
        "        \n",
        "        self._assert_shapes()\n",
        "\n",
        "        self.dws = [dw1, dw2, dw3]\n",
        "        self.dbs = [db1, db2, db3]\n",
        "\n",
        "\n",
        "    def update(self):\n",
        "        \"\"\"\n",
        "        Performs the update step\n",
        "        \"\"\"\n",
        "        self.lin1.w -= self.lr * self.dws[0]\n",
        "        self.lin2.w -= self.lr * self.dws[1]\n",
        "        self.lin3.w -= self.lr * self.dws[2]\n",
        "\n",
        "        self.lin1.b -= self.lr * self.dbs[0]\n",
        "        self.lin2.b -= self.lr * self.dbs[1]\n",
        "        self.lin3.b -= self.lr * self.dbs[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "scrolled": false,
        "id": "mlPD3XtaSaN_",
        "outputId": "71adce37-49f7-4348-bcc4-9caa66778854",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after interation 0 is 0.7024\n",
            "Loss after interation 1 is 0.4431\n",
            "Loss after interation 2 is 0.3046\n",
            "Loss after interation 3 is 0.2305\n",
            "Loss after interation 4 is 0.1933\n",
            "Loss after interation 5 is 0.1690\n",
            "Loss after interation 6 is 0.1506\n",
            "Loss after interation 7 is 0.1361\n",
            "Loss after interation 8 is 0.1245\n",
            "Loss after interation 9 is 0.1150\n",
            "Loss after interation 10 is 0.1069\n",
            "Loss after interation 11 is 0.1000\n",
            "Loss after interation 12 is 0.0940\n",
            "Loss after interation 13 is 0.0887\n",
            "Loss after interation 14 is 0.0840\n",
            "Loss after interation 15 is 0.0799\n",
            "Loss after interation 16 is 0.0761\n",
            "Loss after interation 17 is 0.0727\n",
            "Loss after interation 18 is 0.0695\n",
            "Loss after interation 19 is 0.0666\n",
            "Loss after interation 20 is 0.0639\n",
            "Loss after interation 21 is 0.0615\n",
            "Loss after interation 22 is 0.0592\n",
            "Loss after interation 23 is 0.0571\n",
            "Loss after interation 24 is 0.0551\n",
            "Loss after interation 25 is 0.0533\n",
            "Loss after interation 26 is 0.0516\n",
            "Loss after interation 27 is 0.0500\n",
            "Loss after interation 28 is 0.0485\n",
            "Loss after interation 29 is 0.0472\n",
            "Loss after interation 30 is 0.0459\n",
            "Loss after interation 31 is 0.0447\n",
            "Loss after interation 32 is 0.0435\n",
            "Loss after interation 33 is 0.0425\n",
            "Loss after interation 34 is 0.0415\n",
            "Loss after interation 35 is 0.0405\n",
            "Loss after interation 36 is 0.0396\n",
            "Loss after interation 37 is 0.0388\n",
            "Loss after interation 38 is 0.0380\n",
            "Loss after interation 39 is 0.0372\n",
            "Loss after interation 40 is 0.0365\n",
            "Loss after interation 41 is 0.0358\n",
            "Loss after interation 42 is 0.0351\n",
            "Loss after interation 43 is 0.0345\n",
            "Loss after interation 44 is 0.0339\n",
            "Loss after interation 45 is 0.0334\n",
            "Loss after interation 46 is 0.0328\n",
            "Loss after interation 47 is 0.0323\n",
            "Loss after interation 48 is 0.0318\n",
            "Loss after interation 49 is 0.0314\n",
            "Loss after interation 50 is 0.0309\n",
            "Loss after interation 51 is 0.0305\n",
            "Loss after interation 52 is 0.0301\n",
            "Loss after interation 53 is 0.0297\n",
            "Loss after interation 54 is 0.0293\n",
            "Loss after interation 55 is 0.0289\n",
            "Loss after interation 56 is 0.0285\n",
            "Loss after interation 57 is 0.0282\n",
            "Loss after interation 58 is 0.0279\n",
            "Loss after interation 59 is 0.0275\n"
          ]
        }
      ],
      "source": [
        "nn = Model(learning_rate=0.000005)\n",
        "epochs = 60 # no. of iterations to train\n",
        "\n",
        "for n in range(epochs):\n",
        "    loss , _ = nn.forward(x_train, calc_loss=True, targ=y_train)\n",
        "    nn.backward()\n",
        "    nn.update()\n",
        "    print(f\"Loss after interation {n} is {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "zfL34tQ0SaN_",
        "outputId": "ea254928-4a3f-40e3-aa15-423e08652c22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#collapse\n",
        "plt.plot(nn.losses, color=\"teal\")\n",
        "plt.title(\"Loss per Iteration\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8wFBHgYSaN_"
      },
      "source": [
        "## Computing accuracy of our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3kcN10bSaOA"
      },
      "source": [
        "**Let's check our model performance by computing the `accuracy` on the `validation` dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "P9_RlDvHSaOA"
      },
      "outputs": [],
      "source": [
        "def comp_accuracy(preds, targs):\n",
        "    \"\"\"\n",
        "    Fn that computes the accuracy between the predicted values and the targets\n",
        "    \"\"\"\n",
        "    m = len(targs)\n",
        "    p = np.zeros_like(preds)\n",
        "    # convert probas to 0/1 predictions\n",
        "    for i in range(len(preds)):\n",
        "        if preds[i] > 0.5:\n",
        "            p[i] = 1\n",
        "        else:\n",
        "            p[i] = 0\n",
        "    print(\"Accuracy: \"  + str(np.sum((p == targs)/m)))    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ3eFat9SaOA"
      },
      "source": [
        "computing accuracy on the train set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "S8xk4tfYSaOA",
        "outputId": "1b97e6ec-7f82-4951-c44b-201833d01c20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9922621397552309\n"
          ]
        }
      ],
      "source": [
        "preds = nn.forward(x_train, calc_loss=False) # generate predictions from our model\n",
        "# compute accuracy\n",
        "comp_accuracy(preds, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpcnq5mKSaOA"
      },
      "source": [
        "computing accuracy on the validation set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "2JdczLdxSaOA",
        "outputId": "8a1d7c3e-b9e2-4180-92c6-437884239162",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9914893617021273\n"
          ]
        }
      ],
      "source": [
        "preds = nn.forward(x_valid, calc_loss=False) # generate predictions from our model\n",
        "# compute accuracy\n",
        "comp_accuracy(preds, y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6hBChLzSaOA"
      },
      "source": [
        "> Note: our model achieved a `accuracy` of **`0.99`** on both the `train` and the `validation` set !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EWdo0KiSaOA"
      },
      "source": [
        "## Generating predictions from the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "CSn4JSUOSaOA",
        "outputId": "ed06cbd2-b42e-4b5a-8ba1-9da7c6a93b53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted output: 0\n"
          ]
        }
      ],
      "source": [
        "#collapse\n",
        "test_inp = x_valid[0] # one example from the validation set\n",
        "plt.title(\"Input: \")\n",
        "\n",
        "plt.imshow(test_inp.reshape(28,28), cmap=\"binary\")\n",
        "plt.show()\n",
        "\n",
        "pred = nn.forward(test_inp, calc_loss=False)\n",
        "predicted_val = int(pred > 0.5)\n",
        "print(f\"Predicted output: {predicted_val}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "vhHJs_LvSaOB",
        "outputId": "e5ea2ca9-d0ac-4188-eceb-92f2cf1e4f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted output: 1\n"
          ]
        }
      ],
      "source": [
        "#collapse\n",
        "test_inp = x_valid[1092] # one example from the validation set\n",
        "plt.title(\"Input: \")\n",
        "plt.imshow(test_inp.reshape(28,28), cmap=\"binary\")\n",
        "plt.show()\n",
        "\n",
        "pred = nn.forward(test_inp, calc_loss=False)\n",
        "predicted_val = int(pred > 0.5)\n",
        "print(f\"Predicted output: {predicted_val}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxnId0naSaOB"
      },
      "source": [
        "## Summary:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AFKxkg0SaOB"
      },
      "source": [
        "- We were able to create a model that can identify classify handwritten digits as either 1's or 0's\n",
        "- We successfully computed the `forward` and `backward` progation of a `neural network` from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mdDrqevSaOB"
      },
      "source": [
        "**Thanks for reading !**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}